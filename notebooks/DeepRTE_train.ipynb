{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows you to simply run the [JAX](https://jax.readthedocs.org) implementation of DeepRTE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "The cell below downloads the code from Github and install necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ![ -d deeprte] || git clone --depth=1 https://github.com/mazhengcn/deeprte.git\n",
    "# !cd deeprte && git pull\n",
    "# !pip install -qr deeprte/requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,6\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".70\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import jax\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from jaxline import utils as jl_utils\n",
    "import haiku as hk\n",
    "from deeprte.train import Trainer\n",
    "from deeprte.config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0),\n",
       " StreamExecutorGpuDevice(id=1, process_index=0, slice_index=0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.local_devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "DATA_DIR = \"/workspaces/deeprte/rte_data/matlab/train-scattering-kernel-0309\"\n",
    "DATA_NAMES = [\"train_random_kernel_1.mat\",\"train_random_kernel_2.mat\"]\n",
    "\n",
    "# define train params\n",
    "num_epoch = 1\n",
    "batch_size = 2\n",
    "base_lr = 0.001\n",
    "optimizer = \"adam\"\n",
    "schedule_type = \"exponential\"\n",
    "decay_rate = 0.96\n",
    "transition_steps = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup train config\n",
    "config = get_config()\n",
    "config = config.experiment_kwargs.config\n",
    "config.dataset.source_dir = DATA_DIR\n",
    "config.dataset.data_name_list = DATA_NAMES\n",
    "config.dataset.train.batch_size = batch_size\n",
    "config.training.num_epoch = num_epoch\n",
    "config.training.optimizer.base_lr = base_lr\n",
    "config.training.optimizer.schedule_type = schedule_type\n",
    "config.training.optimizer.optimizer = optimizer\n",
    "config.training.optimizer.decay_kwargs.decay_rate = decay_rate\n",
    "config.training.optimizer.decay_kwargs.transition_steps = transition_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_epoch: 1\n",
       "num_epochs: 8000\n",
       "optimizer:\n",
       "  adam_kwargs: {}\n",
       "  base_lr: 0.001\n",
       "  decay_kwargs:\n",
       "    decay_rate: 0.96\n",
       "    transition_steps: 60000\n",
       "  optimizer: adam\n",
       "  scale_by_batch: false\n",
       "  schedule_type: exponential"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_rng = 0\n",
    "mode = \"train\"\n",
    "\n",
    "e = Trainer(mode=mode, init_rng=init_rng, config=config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = hk.PRNGSequence(42)\n",
    "init_rng = jl_utils.bcast_local_devices(next(rng))\n",
    "e._initialize_training()\n",
    "# e._build_train_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars = []\n",
    "for i in range(num_epoch):\n",
    "    scalar = e.step(jl_utils.bcast_local_devices(i), jl_utils.bcast_local_devices(next(rng)))\n",
    "    scalars[\"global_step\"] = i\n",
    "    scalars.append(scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total loss\n",
    "total_loss = [scalar[\"train_total_loss\"] for scalar in scalars]\n",
    "\n",
    "# plt.plot(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore params\n",
    "params = e._params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define eval model\n",
    "eval_model = jax.jit(lambda params, inputs: e.model.apply(params, None, next(rng), inputs, is_training=False, compute_loss=False,compute_metrics=True,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test import utils\n",
    "from deeprte.model.tf.input_pipeline import load_tf_data\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boundary': (1, 1920),\n",
       " 'boundary_coords': (1920, 4),\n",
       " 'boundary_scattering_kernel': (1, 1920, 24),\n",
       " 'boundary_weights': (1920,),\n",
       " 'phase_coords': (38400, 4),\n",
       " 'position_coords': (1600, 2),\n",
       " 'psi_label': (1, 38400),\n",
       " 'scattering_kernel': (1, 38400, 24),\n",
       " 'self_scattering_kernel': (1, 24, 24),\n",
       " 'sigma': (1, 1600, 2),\n",
       " 'velocity_coords': (24, 2),\n",
       " 'velocity_weights': (24,)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data = load_tf_data(DATA_DIR, DATA_NAMES, normalization=False)\n",
    "features = jax.tree_map(lambda x: jnp.array(x), tf_data)\n",
    "data_feature = features[0]\n",
    "batch = utils.slice_batch(0, data_feature)\n",
    "\n",
    "# visualize shape\n",
    "jax.tree_util.tree_map(lambda x: x.shape, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedTracerError",
     "evalue": "Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type uint32[2] wrapped in a DynamicJaxprTracer to escape the scope of the transformation.\nJAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\nThe function being traced when the value leaked was <lambda> at /tmp/ipykernel_2539128/4288000890.py:2 traced for pmap.\n------------------------------\nThe leaked intermediate value was created on line /tmp/ipykernel_2539128/4288000890.py:2 (<lambda>). \n------------------------------\nWhen the value was created, the final 5 stack frames (most recent last) excluding JAX-internal frames were:\n------------------------------\n/root/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3194 (run_cell_async)\n/root/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3373 (run_ast_nodes)\n/root/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3433 (run_code)\n/tmp/ipykernel_2539128/2715311739.py:1 (<module>)\n/tmp/ipykernel_2539128/4288000890.py:2 (<lambda>)\n------------------------------\n\nTo catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedTracerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ret \u001b[39m=\u001b[39m eval_model(params, batch)\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(params, inputs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# define eval model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m eval_model \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mjit(\u001b[39mlambda\u001b[39;00m params, inputs: e\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mapply(params, \u001b[39mNone\u001b[39;00m, \u001b[39mnext\u001b[39;49m(rng), inputs, is_training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, compute_loss\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,compute_metrics\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/base.py:910\u001b[0m, in \u001b[0;36mPRNGSequence.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PRNGKey:\n\u001b[1;32m    909\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subkeys:\n\u001b[0;32m--> 910\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreserve(config\u001b[39m.\u001b[39;49mget_config()\u001b[39m.\u001b[39;49mrng_reserve_size)\n\u001b[1;32m    911\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subkeys\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/base.py:883\u001b[0m, in \u001b[0;36mPRNGSequence.reserve\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39m\"\"\"Splits additional ``num`` keys for later use.\"\"\"\u001b[39;00m\n\u001b[1;32m    874\u001b[0m \u001b[39mif\u001b[39;00m num \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    875\u001b[0m   \u001b[39m# When storing keys we adopt a pattern of key0 being reserved for future\u001b[39;00m\n\u001b[1;32m    876\u001b[0m   \u001b[39m# splitting and all other keys being provided to the user in linear order.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m   \u001b[39m#\u001b[39;00m\n\u001b[1;32m    882\u001b[0m   \u001b[39m# Where subkey1->subkey4 are provided to the user in order when requested.\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m   new_keys \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(jax\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49msplit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_key, num \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m))\n\u001b[1;32m    884\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key \u001b[39m=\u001b[39m new_keys[\u001b[39m0\u001b[39m]\n\u001b[1;32m    885\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subkeys\u001b[39m.\u001b[39mextend(new_keys[\u001b[39m1\u001b[39m:])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jax/_src/random.py:212\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(key, num)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(key: KeyArray, num: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m KeyArray:\n\u001b[1;32m    202\u001b[0m   \u001b[39m\"\"\"Splits a PRNG key into `num` new keys by adding a leading axis.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39m    An array-like object of `num` new PRNG keys.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m   key, wrapped \u001b[39m=\u001b[39m _check_prng_key(key)\n\u001b[1;32m    213\u001b[0m   \u001b[39mreturn\u001b[39;00m _return_prng_keys(wrapped, _split(key, num))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jax/_src/random.py:74\u001b[0m, in \u001b[0;36m_check_prng_key\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_custom_prng:\n\u001b[1;32m     70\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     71\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mRaw arrays as random keys to jax.random functions are deprecated. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mAssuming valid threefry2x32 key for now.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     73\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m   \u001b[39mreturn\u001b[39;00m prng\u001b[39m.\u001b[39;49mrandom_wrap(key, impl\u001b[39m=\u001b[39;49mdefault_prng_impl()), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39munexpected PRNG key type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(key)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jax/_src/prng.py:754\u001b[0m, in \u001b[0;36mrandom_wrap\u001b[0;34m(base_arr, impl)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_wrap\u001b[39m(base_arr, \u001b[39m*\u001b[39m, impl):\n\u001b[1;32m    753\u001b[0m   _check_prng_key_data(impl, base_arr)\n\u001b[0;32m--> 754\u001b[0m   \u001b[39mreturn\u001b[39;00m random_wrap_p\u001b[39m.\u001b[39;49mbind(base_arr, impl\u001b[39m=\u001b[39;49mimpl)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jax/interpreters/partial_eval.py:1486\u001b[0m, in \u001b[0;36mDynamicJaxprTracer._assert_live\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assert_live\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1485\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trace\u001b[39m.\u001b[39mmain\u001b[39m.\u001b[39mjaxpr_stack:  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1486\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39mescaped_tracer_error(\u001b[39mself\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mUnexpectedTracerError\u001b[0m: Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type uint32[2] wrapped in a DynamicJaxprTracer to escape the scope of the transformation.\nJAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\nThe function being traced when the value leaked was <lambda> at /tmp/ipykernel_2539128/4288000890.py:2 traced for pmap.\n------------------------------\nThe leaked intermediate value was created on line /tmp/ipykernel_2539128/4288000890.py:2 (<lambda>). \n------------------------------\nWhen the value was created, the final 5 stack frames (most recent last) excluding JAX-internal frames were:\n------------------------------\n/root/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3194 (run_cell_async)\n/root/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3373 (run_ast_nodes)\n/root/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3433 (run_code)\n/tmp/ipykernel_2539128/2715311739.py:1 (<module>)\n/tmp/ipykernel_2539128/4288000890.py:2 (<lambda>)\n------------------------------\n\nTo catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError"
     ]
    }
   ],
   "source": [
    "ret = eval_model(params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'metrics': {'mse': (2, 1), 'rmspe': (2, 1)},\n",
       "  'predicted_solution': (2, 1, 120)},\n",
       " {})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_util.tree_map(lambda x: x.shape, ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardedDeviceArray([[8.989382 ],\n",
       "                    [0.9979299]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[0][\"metrics\"][\"rmspe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
