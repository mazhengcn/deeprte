{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611f0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f6ed285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "# IMPORTANT: Replace these placeholders with the actual paths to your .mat files\n",
    "mat_file_paths = [\n",
    "    \"/home/zhuyekun/projects/repos/deeprte/data/raw/train/merge/shuffled_500_samples.mat\",  # Replace with your first file\n",
    "    \"/home/zhuyekun/projects/repos/deeprte/data/raw/train/S-g0.01/S.mat\",  # Replace with your second file\n",
    "    \"/home/zhuyekun/projects/repos/deeprte/data/raw/train/S-g0.95/S-g0.95.mat\",   # Replace with your third file\n",
    "]\n",
    "\n",
    "# IMPORTANT: Replace this with the desired output path and filename\n",
    "output_path = \"/home/zhuyekun/projects/repos/deeprte/data/raw/train/S_merge/merged_train.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1662a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = {k: v for k, v in scipy.io.loadmat(mat_file_paths[0]).items() if not k.startswith('__')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387022d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['config', 'ct', 'omega_prime', 'phi', 'psi_bc', 'psi_label', 'rand_params', 'rv_prime', 'scattering_kernel', 'sigma_a', 'sigma_t', 'st', 'w_angle', 'x', 'y'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44fff6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': (1, 1),\n",
       " 'ct': (24, 1),\n",
       " 'omega_prime': (164, 12),\n",
       " 'phi': (500, 41, 41),\n",
       " 'psi_bc': (500, 164, 12),\n",
       " 'psi_label': (500, 41, 41, 24),\n",
       " 'rand_params': (1, 1000),\n",
       " 'rv_prime': (164, 12, 4),\n",
       " 'scattering_kernel': (500, 24, 24),\n",
       " 'sigma_a': (500, 41, 41),\n",
       " 'sigma_t': (500, 41, 41),\n",
       " 'st': (24, 1),\n",
       " 'w_angle': (24, 1),\n",
       " 'x': (1, 41),\n",
       " 'y': (1, 41)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tree\n",
    "tree.map_structure(lambda x: x.shape if isinstance(x, np.ndarray) else x, merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb3eace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base file: /home/zhuyekun/projects/repos/deeprte/data/raw/train/merge/shuffled_500_samples.mat\n",
      "Will concatenate the following keys: ['scattering_kernel', 'sigma_a', 'sigma_t', 'phi', 'psi_bc', 'psi_label']\n",
      "Merging file: /home/zhuyekun/projects/repos/deeprte/data/raw/train/S-g0.01/S.mat\n",
      "Merging file: /home/zhuyekun/projects/repos/deeprte/data/raw/train/S-g0.95/S-g0.95.mat\n",
      "Saving merged data to: /home/zhuyekun/projects/repos/deeprte/data/raw/train/S_merge/merged_train.mat\n",
      "Merging complete!\n",
      "\n",
      "Verifying merged file...\n",
      "Key: 'config', Shape: (1, 1)\n",
      "Key: 'ct', Shape: (24, 1)\n",
      "Key: 'omega_prime', Shape: (164, 12)\n",
      "Key: 'phi', Shape: (1000, 41, 41)\n",
      "Key: 'psi_bc', Shape: (1000, 164, 12)\n",
      "Key: 'psi_label', Shape: (1000, 41, 41, 24)\n",
      "Key: 'rand_params', Shape: (1, 1000)\n",
      "Key: 'rv_prime', Shape: (164, 12, 4)\n",
      "Key: 'scattering_kernel', Shape: (1000, 24, 24)\n",
      "Key: 'sigma_a', Shape: (1000, 41, 41)\n",
      "Key: 'sigma_t', Shape: (1000, 41, 41)\n",
      "Key: 'st', Shape: (24, 1)\n",
      "Key: 'w_angle', Shape: (24, 1)\n",
      "Key: 'x', Shape: (1, 41)\n",
      "Key: 'y', Shape: (1, 41)\n"
     ]
    }
   ],
   "source": [
    "# Check if there are files to merge\n",
    "if not mat_file_paths or not all(isinstance(p, str) for p in mat_file_paths):\n",
    "    print(\"Error: Please specify the paths to your .mat files in the 'mat_file_paths' list.\")\n",
    "else:\n",
    "    # Load the first file to initialize the merged_data dictionary\n",
    "    base_file = mat_file_paths[0]\n",
    "    print(f\"Loading base file: {base_file}\")\n",
    "\n",
    "    try:\n",
    "        # Initialize merged_data with all contents of the first file\n",
    "        merged_data = {k: v for k, v in scipy.io.loadmat(base_file).items() if not k.startswith('__')}\n",
    "\n",
    "        # Define the specific keys that need to be concatenated\n",
    "        keys_to_concatenate = ['scattering_kernel', 'sigma_a', 'sigma_t', 'phi', 'psi_bc', 'psi_label']\n",
    "        print(f\"Will concatenate the following keys: {keys_to_concatenate}\")\n",
    "\n",
    "        # Iterate over the rest of the files and merge\n",
    "        for file_path in mat_file_paths[1:]:\n",
    "            print(f\"Merging file: {file_path}\")\n",
    "            try:\n",
    "                data_to_merge = scipy.io.loadmat(file_path)\n",
    "                # Only iterate over the keys specified for concatenation\n",
    "                for key in keys_to_concatenate:\n",
    "                    if key in merged_data and key in data_to_merge:\n",
    "                        # Concatenate along the first dimension (axis=0)\n",
    "                        merged_data[key] = np.concatenate(\n",
    "                            (merged_data[key], data_to_merge[key]), axis=0\n",
    "                        )\n",
    "                    else:\n",
    "                        print(f\"Warning: Key '{key}' not found in both base file and {file_path}. Skipping concatenation for this key.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: File not found at {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing {file_path}: {e}\")\n",
    "\n",
    "        # --- 3. Save the merged file ---\n",
    "        print(f\"Saving merged data to: {output_path}\")\n",
    "        # Ensure the output directory exists\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        scipy.io.savemat(output_path, merged_data)\n",
    "        print(\"Merging complete!\")\n",
    "\n",
    "        # --- 4. Verification (Optional) ---\n",
    "        print(\"\\nVerifying merged file...\")\n",
    "        verification_data = scipy.io.loadmat(output_path)\n",
    "        for key, value in verification_data.items():\n",
    "            if not key.startswith('__'):\n",
    "                print(f\"Key: '{key}', Shape: {value.shape}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Base file not found at {base_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1adc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
