{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import haiku as hk\n",
    "import tensorflow as tf\n",
    "from deeprte.config import get_config\n",
    "from deeprte.model.modules import DeepRTE\n",
    "from deeprte.model.tf.input_pipeline import load_tf_data\n",
    "from deeprte.model.data import flat_params_to_haiku\n",
    "\n",
    "from deeprte.model.tf.rte_features import BATCH_FEATURE_NAMES,COLLOCATION_FEATURE_NAMES,BOUNDARY_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeprte.model.tf.rte_dataset import (\n",
    "    TensorDict,\n",
    "    divide_batch_feat,\n",
    "    make_collocation_axis,\n",
    "    make_boudary_sample_axis,\n",
    "    np_to_tensor_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeprte.model.tf.data_transforms import construct_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"/workspaces/deeprte/rte_data/matlab/eval-data/scattering-kernel/0311/\"\n",
    "data_name_list = [\"test_bc1.mat\"]\n",
    "# data_name_list = [\"test_bc1_fixedvar_scattering_kernel.mat\"]\n",
    "# data_name_list = [\"test_itr.mat\"]\n",
    "\n",
    "PARAMS_FILE = \"/workspaces/deeprte/ckpts/train_scattering_kernel_2023-02-16T14:04:06/models/latest/step_1200000_2023-02-19T22:37:17/params.npz\"\n",
    "CONFIG_PATH = \"/workspaces/deeprte/ckpts/train_scattering_kernel_2023-02-16T14:04:06/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeprte.data.pipeline import DataPipeline\n",
    "\n",
    "data_pipeline = DataPipeline(source_dir, data_name_list)\n",
    "\n",
    "data = data_pipeline.process(\n",
    "    pre_shuffle=False,\n",
    "    pre_shuffle_seed=0,\n",
    "    is_split_test_samples=False,\n",
    "    num_test_samples=None,\n",
    "    normalization=False,\n",
    "    save_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'boundary': (10, 1920),\n",
       "  'boundary_coords': (1920, 4),\n",
       "  'boundary_scattering_kernel': (10, 1920, 24),\n",
       "  'boundary_weights': (1920,),\n",
       "  'phase_coords': (38400, 4),\n",
       "  'position_coords': (1600, 2),\n",
       "  'psi_label': (10, 38400),\n",
       "  'scattering_kernel': (10, 38400, 24),\n",
       "  'self_scattering_kernel': (10, 24, 24),\n",
       "  'sigma': (10, 1600, 2),\n",
       "  'velocity_coords': (24, 2),\n",
       "  'velocity_weights': (24,)},\n",
       " {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data = load_tf_data(source_dir, data_name_list, normalization=False)\n",
    "features = jax.tree_map(lambda x: np.array(x), tf_data)\n",
    "jax.tree_util.tree_map(lambda x: x.shape, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature = features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01250000053551048"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data_feature[\"boundary_weights\"][:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2554414 ,  0.28708965,  0.69309574,  0.2513426 ,  0.68668073,\n",
       "        0.9380233 ,  0.2554414 ,  0.69309574,  0.28708965,  0.9380233 ,\n",
       "        0.68668073,  0.2513426 , -0.2554414 , -0.28708965, -0.69309574,\n",
       "       -0.2513426 , -0.68668073, -0.9380233 , -0.2554414 , -0.69309574,\n",
       "       -0.28708965, -0.9380233 , -0.68668073, -0.2513426 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feature[\"velocity_coords\"][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_data, unbatched_data = divide_batch_feat(data_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(batched_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.batch(1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = construct_batch(unbatched_feat=unbatched_data,\n",
    "            collocation_sizes=(12,13),\n",
    "            collocation_features=(make_collocation_axis(),make_boudary_sample_axis(),),\n",
    "            total_grid_sizes=(40*40*24,1920) ,\n",
    "            generator=tf.random.Generator.from_seed(seed=0),\n",
    "            is_training=True,\n",
    "            is_replacing=(True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boundary': TensorSpec(shape=(1, 1920), dtype=tf.float32, name=None),\n",
       " 'boundary_scattering_kernel': TensorSpec(shape=(1, 1920, 24), dtype=tf.float32, name=None),\n",
       " 'psi_label': TensorSpec(shape=(1, 12), dtype=tf.float32, name=None),\n",
       " 'scattering_kernel': TensorSpec(shape=(1, 12, 24), dtype=tf.float32, name=None),\n",
       " 'self_scattering_kernel': TensorSpec(shape=(1, 24, 24), dtype=tf.float32, name=None),\n",
       " 'sigma': TensorSpec(shape=(1, 1600, 2), dtype=tf.float32, name=None),\n",
       " 'boundary_coords': TensorSpec(shape=(1920, 4), dtype=tf.float32, name=None),\n",
       " 'boundary_weights': TensorSpec(shape=(1920,), dtype=tf.float32, name=None),\n",
       " 'phase_coords': TensorSpec(shape=(12, 4), dtype=tf.float32, name=None),\n",
       " 'position_coords': TensorSpec(shape=(1600, 2), dtype=tf.float32, name=None),\n",
       " 'velocity_coords': TensorSpec(shape=(24, 2), dtype=tf.float32, name=None),\n",
       " 'velocity_weights': TensorSpec(shape=(24,), dtype=tf.float32, name=None),\n",
       " 'sampled_boundary_coords': TensorSpec(shape=(13, 4), dtype=tf.float32, name=None),\n",
       " 'sampled_boundary': TensorSpec(shape=(1, 13), dtype=tf.float32, name=None),\n",
       " 'sampled_boundary_scattering_kernel': TensorSpec(shape=(1, 13, 24), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.batch(4, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boundary': TensorSpec(shape=(4, 1, 1920), dtype=tf.float32, name=None),\n",
       " 'boundary_scattering_kernel': TensorSpec(shape=(4, 1, 1920, 24), dtype=tf.float32, name=None),\n",
       " 'psi_label': TensorSpec(shape=(4, 1, 12), dtype=tf.float32, name=None),\n",
       " 'scattering_kernel': TensorSpec(shape=(4, 1, 12, 24), dtype=tf.float32, name=None),\n",
       " 'self_scattering_kernel': TensorSpec(shape=(4, 1, 24, 24), dtype=tf.float32, name=None),\n",
       " 'sigma': TensorSpec(shape=(4, 1, 1600, 2), dtype=tf.float32, name=None),\n",
       " 'boundary_coords': TensorSpec(shape=(4, 1920, 4), dtype=tf.float32, name=None),\n",
       " 'boundary_weights': TensorSpec(shape=(4, 1920), dtype=tf.float32, name=None),\n",
       " 'phase_coords': TensorSpec(shape=(4, 12, 4), dtype=tf.float32, name=None),\n",
       " 'position_coords': TensorSpec(shape=(4, 1600, 2), dtype=tf.float32, name=None),\n",
       " 'velocity_coords': TensorSpec(shape=(4, 24, 2), dtype=tf.float32, name=None),\n",
       " 'velocity_weights': TensorSpec(shape=(4, 24), dtype=tf.float32, name=None),\n",
       " 'sampled_boundary_coords': TensorSpec(shape=(4, 13, 4), dtype=tf.float32, name=None),\n",
       " 'sampled_boundary': TensorSpec(shape=(4, 1, 13), dtype=tf.float32, name=None),\n",
       " 'sampled_boundary_scattering_kernel': TensorSpec(shape=(4, 1, 13, 24), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeprte.model.tf.input_pipeline import tf_data_to_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf_data_to_generator(tf_data[0], is_training=True, batch_sizes=[1,4], collocation_size=12, bc_collocation_size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sigma': (1, 4, 1600, 2),\n",
       " 'psi_label': (1, 4, 12),\n",
       " 'scattering_kernel': (1, 4, 12, 24),\n",
       " 'boundary_scattering_kernel': (1, 4, 1920, 24),\n",
       " 'self_scattering_kernel': (1, 4, 24, 24),\n",
       " 'boundary': (1, 4, 1920),\n",
       " 'position_coords': (1, 1600, 2),\n",
       " 'velocity_coords': (1, 24, 2),\n",
       " 'phase_coords': (1, 12, 4),\n",
       " 'boundary_coords': (1, 1920, 4),\n",
       " 'boundary_weights': (1, 1920),\n",
       " 'velocity_weights': (1, 24),\n",
       " 'sampled_boundary_coords': (1, 13, 4),\n",
       " 'sampled_boundary': (1, 4, 13),\n",
       " 'sampled_boundary_scattering_kernel': (1, 4, 13, 24)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nest.map_structure(lambda x: x.shape, next(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_inputs = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from deeprte.config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "config = config.experiment_kwargs.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = hk.PRNGSequence(jax.random.PRNGKey(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(batch, is_training):\n",
    "    out = DeepRTE(config.model)(batch, is_training=is_training, compute_loss=False, compute_metrics=False)\n",
    "    return out\n",
    "\n",
    "forward = hk.transform(forward_fn)\n",
    "apply = jax.jit(functools.partial(forward.apply, is_training = False))\n",
    "init = jax.jit(functools.partial(forward.init, is_training = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (2 of them) had size 4, e.g. axis 0 of args[0][0]['psi_label'] of type float32[4,12];\n  * one axis had size 1: axis 0 of args[0][0]['phase_coords'] of type float32[1,12,4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m params \u001b[39m=\u001b[39m init(\u001b[39mnext\u001b[39;49m(rng), dummy_inputs)\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/transform.py:114\u001b[0m, in \u001b[0;36mwithout_state.<locals>.init_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 114\u001b[0m   params, state \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49minit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    115\u001b[0m   \u001b[39mif\u001b[39;00m state:\n\u001b[1;32m    116\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf your transformed function uses `hk.\u001b[39m\u001b[39m{\u001b[39m\u001b[39mget,set}_state` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mthen use `hk.transform_with_state`.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/transform.py:338\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.init_fn\u001b[0;34m(rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m base\u001b[39m.\u001b[39mnew_context(rng\u001b[39m=\u001b[39mrng) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m    337\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    339\u001b[0m   \u001b[39mexcept\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    340\u001b[0m     \u001b[39mraise\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m, in \u001b[0;36mforward_fn\u001b[0;34m(batch, is_training)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fn\u001b[39m(batch, is_training):\n\u001b[0;32m----> 2\u001b[0m     out \u001b[39m=\u001b[39m DeepRTE(config\u001b[39m.\u001b[39;49mmodel)(batch, is_training\u001b[39m=\u001b[39;49mis_training, compute_loss\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, compute_metrics\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      3\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/module.py:426\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m   \u001b[39mif\u001b[39;00m method_name \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__call__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    424\u001b[0m     f \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mnamed_call(f, name\u001b[39m=\u001b[39mmethod_name)\n\u001b[0;32m--> 426\u001b[0m out \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    428\u001b[0m \u001b[39m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[39m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[39m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39mif\u001b[39;00m module_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/module.py:272\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 272\u001b[0m   \u001b[39mreturn\u001b[39;00m bound_method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    274\u001b[0m ctx \u001b[39m=\u001b[39m MethodContext(module\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m                     method_name\u001b[39m=\u001b[39mmethod_name,\n\u001b[1;32m    276\u001b[0m                     orig_method\u001b[39m=\u001b[39mbound_method)\n\u001b[1;32m    277\u001b[0m interceptor_stack_copy \u001b[39m=\u001b[39m interceptor_stack\u001b[39m.\u001b[39mclone()\n",
      "File \u001b[0;32m/workspaces/deeprte/deeprte/model/modules.py:85\u001b[0m, in \u001b[0;36mDeepRTE.__call__\u001b[0;34m(self, batch, is_training, compute_loss, compute_metrics)\u001b[0m\n\u001b[1;32m     76\u001b[0m batch_axes \u001b[39m=\u001b[39m get_vmap_axes(batch\u001b[39m.\u001b[39mkeys(), BATCH_FEATURE_NAMES)\n\u001b[1;32m     78\u001b[0m batched_rte_op \u001b[39m=\u001b[39m hk\u001b[39m.\u001b[39mvmap(\n\u001b[1;32m     79\u001b[0m     mapping\u001b[39m.\u001b[39msharded_map(\n\u001b[1;32m     80\u001b[0m         rte_op, shard_size\u001b[39m=\u001b[39mlow_memory, in_axes\u001b[39m=\u001b[39mcollocation_axes\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     split_rng\u001b[39m=\u001b[39m(\u001b[39mnot\u001b[39;00m hk\u001b[39m.\u001b[39mrunning_init()),\n\u001b[1;32m     84\u001b[0m )\n\u001b[0;32m---> 85\u001b[0m predictions \u001b[39m=\u001b[39m batched_rte_op(batch)\n\u001b[1;32m     87\u001b[0m ret[\u001b[39m\"\u001b[39m\u001b[39mpredicted_solution\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m predictions\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m compute_loss:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/stateful.py:845\u001b[0m, in \u001b[0;36mvmap.<locals>.mapped_fun\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mhk.vmap does not support setting split_rng to True \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    838\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mduring initialization because it assumes parameters \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    839\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mare always shared along the mapped dimension. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    842\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m`split_rng=(not hk.running_init())`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m                      ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    844\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 845\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m    847\u001b[0m \u001b[39mif\u001b[39;00m split_rng:\n\u001b[1;32m    848\u001b[0m   state \u001b[39m=\u001b[39m InternalState(state\u001b[39m.\u001b[39mparams, state\u001b[39m.\u001b[39mstate, saved_rng)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/stateful.py:833\u001b[0m, in \u001b[0;36mvmap.<locals>.mapped_fun\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    830\u001b[0m   state \u001b[39m=\u001b[39m InternalState(state\u001b[39m.\u001b[39mparams, state\u001b[39m.\u001b[39mstate, rng)\n\u001b[1;32m    832\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 833\u001b[0m   out, state \u001b[39m=\u001b[39m mapped_pure_fun(args, state)\n\u001b[1;32m    834\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    835\u001b[0m   \u001b[39mif\u001b[39;00m split_rng \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m base\u001b[39m.\u001b[39mparams_frozen() \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mout_axes\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n\u001b[1;32m    836\u001b[0m     \u001b[39m# TODO(lenamartens): add error for state too.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/stateful.py:812\u001b[0m, in \u001b[0;36mvmap.<locals>.pure_fun\u001b[0;34m(args, state_in)\u001b[0m\n\u001b[1;32m    808\u001b[0m   state_in \u001b[39m=\u001b[39m InternalState(state_in\u001b[39m.\u001b[39mparams, state_in\u001b[39m.\u001b[39mstate, rng)\n\u001b[1;32m    810\u001b[0m \u001b[39mwith\u001b[39;00m temporary_internal_state(state_in), \\\n\u001b[1;32m    811\u001b[0m      base\u001b[39m.\u001b[39mpush_jax_trace_level():\n\u001b[0;32m--> 812\u001b[0m   out \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    813\u001b[0m   state_out \u001b[39m=\u001b[39m difference(state_in, internal_state())\n\u001b[1;32m    814\u001b[0m   \u001b[39mreturn\u001b[39;00m out, state_out\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/stateful.py:845\u001b[0m, in \u001b[0;36mvmap.<locals>.mapped_fun\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mhk.vmap does not support setting split_rng to True \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    838\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mduring initialization because it assumes parameters \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    839\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mare always shared along the mapped dimension. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    842\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m`split_rng=(not hk.running_init())`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m                      ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    844\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 845\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m    847\u001b[0m \u001b[39mif\u001b[39;00m split_rng:\n\u001b[1;32m    848\u001b[0m   state \u001b[39m=\u001b[39m InternalState(state\u001b[39m.\u001b[39mparams, state\u001b[39m.\u001b[39mstate, saved_rng)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/haiku/_src/stateful.py:833\u001b[0m, in \u001b[0;36mvmap.<locals>.mapped_fun\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    830\u001b[0m   state \u001b[39m=\u001b[39m InternalState(state\u001b[39m.\u001b[39mparams, state\u001b[39m.\u001b[39mstate, rng)\n\u001b[1;32m    832\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 833\u001b[0m   out, state \u001b[39m=\u001b[39m mapped_pure_fun(args, state)\n\u001b[1;32m    834\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    835\u001b[0m   \u001b[39mif\u001b[39;00m split_rng \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m base\u001b[39m.\u001b[39mparams_frozen() \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mout_axes\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n\u001b[1;32m    836\u001b[0m     \u001b[39m# TODO(lenamartens): add error for state too.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jax/_src/api.py:1754\u001b[0m, in \u001b[0;36m_mapped_axis_size\u001b[0;34m(fn, tree, vals, dims, name)\u001b[0m\n\u001b[1;32m   1752\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1753\u001b[0m     msg\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  * some axes (\u001b[39m\u001b[39m{\u001b[39;00mct\u001b[39m}\u001b[39;00m\u001b[39m of them) had size \u001b[39m\u001b[39m{\u001b[39;00msz\u001b[39m}\u001b[39;00m\u001b[39m, e.g. axis \u001b[39m\u001b[39m{\u001b[39;00max\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m;\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1754\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(msg)[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (2 of them) had size 4, e.g. axis 0 of args[0][0]['psi_label'] of type float32[4,12];\n  * one axis had size 1: axis 0 of args[0][0]['phase_coords'] of type float32[1,12,4]"
     ]
    }
   ],
   "source": [
    "params = init(next(rng), dummy_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
